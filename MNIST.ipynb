{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python2\n",
    "\n",
    "# setting up compute backend \n",
    "\n",
    "from neon.backends import gen_backend\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "be = gen_backend(batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our data\n",
    "\n",
    "from neon.data import MNIST\n",
    "\n",
    "mnist = MNIST(path='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting into train and test\n",
    "train_set = mnist.train_iter\n",
    "valid_set = mnist.valid_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing weights\n",
    "# Gaussian distribution with mean = 0 and S.Deviation = 0.01\n",
    "\n",
    "from neon.initializers import Gaussian\n",
    "\n",
    "init_norm = Gaussian(loc=0.0, scale=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architecture - multi layer perceptron with fully connected layers\n",
    "# Affine - Fully connected Layer\n",
    "# Rectlin - Rectified Linear Activation Function\n",
    "# Softmax - ensure sum(outputs) = 1 and outputs within range [0,1]\n",
    "\n",
    "from neon.layers import Affine\n",
    "from neon.transforms import Rectlin, Softmax\n",
    "\n",
    "layers = []\n",
    "layers.append(Affine(nout=10, init=init_norm, activation=Rectlin()))\n",
    "layers.append(Affine(nout=10, init=init_norm,\n",
    "                     activation=Softmax()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize model object\n",
    "\n",
    "from neon.models import Model\n",
    "\n",
    "mlp = Model(layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function - Cross Entropy Loss and Generalized Cost Layer\n",
    "\n",
    "from neon.layers import GeneralizedCost\n",
    "from neon.transforms import CrossEntropyMulti\n",
    "\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rules - stochastic gradient descent \n",
    "# learning rate = 0.1 , momentum coefficient = 0.9\n",
    "\n",
    "from neon.optimizers import GradientDescentMomentum\n",
    "\n",
    "optimizer = GradientDescentMomentum(0.1, momentum_coef=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API Callbacks - calls operations during model fit\n",
    "\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "\n",
    "callbacks = Callbacks(mlp, eval_set=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   [Train |████████████████████| 1875/1875 batches, 0.75 cost, 4.44s]\n",
      "Epoch 1   [Train |████████████████████| 1875/1875 batches, 0.44 cost, 5.26s]\n",
      "Epoch 2   [Train |████████████████████| 1875/1875 batches, 0.40 cost, 4.99s]\n",
      "Epoch 3   [Train |████████████████████| 1875/1875 batches, 0.69 cost, 5.11s]\n",
      "Epoch 4   [Train |████████████████████| 1875/1875 batches, 0.50 cost, 5.11s]\n",
      "Epoch 5   [Train |████████████████████| 1875/1875 batches, 0.44 cost, 5.21s]\n",
      "Epoch 6   [Train |████████████████████| 1875/1875 batches, 0.48 cost, 6.01s]\n",
      "Epoch 7   [Train |████████████████████| 1875/1875 batches, 0.46 cost, 6.33s]\n",
      "Epoch 8   [Train |████████████████████| 1875/1875 batches, 0.29 cost, 5.52s]\n",
      "Epoch 9   [Train |████████████████████| 1875/1875 batches, 0.59 cost, 5.56s]\n"
     ]
    }
   ],
   "source": [
    "# training our model\n",
    "# GRADED FUNCTION\n",
    "mlp.fit(train_set, optimizer=optimizer, num_epochs=10, cost=cost, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting our outputs\n",
    "\n",
    "results = mlp.get_outputs(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification error = 15.6%\n"
     ]
    }
   ],
   "source": [
    "# evaluating model performance using misclassification rate\n",
    "\n",
    "from neon.transforms import Misclassification\n",
    "\n",
    "error = mlp.eval(valid_set, metric=Misclassification())*100\n",
    "print('Misclassification error = %.1f%%' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "# new digit image\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# download image\n",
    "url = \"http://datawrangling.s3.amazonaws.com/sample_digit.png\"\n",
    "urllib.request.urlretrieve(url, filename=\"data/digit.jpg\")\n",
    "\n",
    "# scale to 28x28 pixels\n",
    "img = Image.open(\"data/digit.jpg\")\n",
    "img.thumbnail((28, 28))\n",
    "\n",
    "digit = np.asarray(img, dtype=np.float32)[:, :, 0]\n",
    "\n",
    "# reshape to a single feature vector\n",
    "digit = digit.reshape(784, 1)\n",
    "\n",
    "# store digit into a GPU tensor\n",
    "x_new = be.zeros((28*28, batch_size), dtype=np.float32)\n",
    "x_new[:, 0] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model final layer was: [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "The most probable guess is digit: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121f09f60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c715f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing our model\n",
    "# forward pass through the model\n",
    "outputs = mlp.fprop(x_new)\n",
    "outputs = outputs.get()[:, 0]\n",
    "\n",
    "# examine the output of the model for this image\n",
    "print(\"Model final layer was: {}\".format(outputs))\n",
    "print(\"The most probable guess is digit: {}\".format(np.argmax(outputs)))\n",
    "plt.figure(2)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
